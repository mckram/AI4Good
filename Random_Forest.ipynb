{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9209a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns #visualisation\n",
    "import matplotlib.pyplot as plt #visualisation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.utils import resample\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import math \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "%matplotlib inline \n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d34fc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary(df, min):\n",
    "  for i in min: \n",
    "    df.loc[df.REASON == i, 'REASON'] = 0\n",
    "  df.loc[df.REASON != 0, 'REASON'] = 1\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2262c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a6cf64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.REASON != 7]\n",
    "data = data.loc[:, data.columns != 'CASEID']\n",
    "data= data.loc[:, data.columns != 'Unnamed: 0']\n",
    "data= data.loc[:, data.columns != 'ADMYR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b579160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are the values we want to predict\n",
    "labels = np.array(data['REASON'])\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= data.drop('REASON', axis = 1)\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "# Convert to numpy array\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bc42ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5e58b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c344d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7a7bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(X_test)\n",
    "# Calculate the absolute errors\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7a55bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Create heatmap from the confusion matrix\n",
    "%matplotlib inline\n",
    "class_names=[False, True] # name  of classes\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\", fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = [0.5, 1.5]\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c542cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model for treatment effective/not effective\n",
    "data_eff =  data[data['REASON'].isin([1,2])] \n",
    "data_eff['REASON'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33c7f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eff, test_eff = train_test_split(data_eff, test_size=0.2, shuffle=True)\n",
    "\n",
    "train_eff['REASON'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4081a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_majority = train_eff[train_eff.REASON==1]\n",
    "df_minority = train_eff[train_eff.REASON==2]\n",
    " \n",
    "# Upsample minority class\n",
    "df_min_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=115835,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_resampled_eff = pd.concat([df_min_upsampled, df_majority])\n",
    " \n",
    "# Display new class counts\n",
    "df_resampled_eff.REASON.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6ac323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are the values we want to predict\n",
    "y_train_eff = np.array(df_resampled_eff['REASON'])\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "X_train_eff = df_resampled_eff.drop('REASON', axis = 1)\n",
    "# Saving feature names for later use\n",
    "feature_list_train_eff = list(X_train_eff.columns)\n",
    "# Convert to numpy array\n",
    "X_train_eff = np.array(X_train_eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae12d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are the values we want to predict\n",
    "y_test_eff = np.array(test_eff['REASON'])\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "X_test_eff = test_eff.drop('REASON', axis = 1)\n",
    "# Saving feature names for later use\n",
    "feature_list_train_eff = list(X_test_eff.columns)\n",
    "# Convert to numpy array\n",
    "X_test_eff = np.array(X_test_eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eebf80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res = rf.fit(X_train_eff, y_train_eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec799d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_eff = model_res.predict(X_test_eff)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test_eff, y_pred_eff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d9a9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "cm = metrics.confusion_matrix(y_test_eff, y_pred_eff)\n",
    "disc = ConfusionMatrixDisplay(cm)\n",
    "disc.plot()\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8301217",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd = data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbead3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary(nd,[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c38b8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(nd, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd59ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_majority = train[train.REASON==1]\n",
    "df_minority = train[train.REASON==0]\n",
    " \n",
    "# Upsample minority class\n",
    "df_maj_downsampled = resample(df_majority, \n",
    "                                 replace=False,     # sample with replacement\n",
    "                                 n_samples=1000,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "# Upsample minority class\n",
    "df_min_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=1000,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_resampled = pd.concat([df_min_upsampled, df_maj_downsampled])\n",
    " \n",
    "# Display new class counts\n",
    "df_resampled.REASON.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e840ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are the values we want to predict\n",
    "y_train_nd = np.array(df_resampled['REASON'])\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "X_train_nd = df_resampled.drop('REASON', axis = 1)\n",
    "# Saving feature names for later use\n",
    "feature_list_train_nd = list(X_train_nd.columns)\n",
    "# Convert to numpy array\n",
    "X_train_nd = np.array(X_train_nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd37d320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are the values we want to predict\n",
    "y_test_nd = np.array(test['REASON'])\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "X_test_nd = test.drop('REASON', axis = 1)\n",
    "# Saving feature names for later use\n",
    "feature_list_train_nd = list(X_test_nd.columns)\n",
    "# Convert to numpy array\n",
    "X_test_nd = np.array(X_test_nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593b641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Parameters\n",
    "max_depth=[2, 8, 16]\n",
    "n_estimators = [64, 128, 256]\n",
    "param_grid = dict(max_depth=max_depth, n_estimators=n_estimators)\n",
    "\n",
    "# Build the grid search\n",
    "dfrst = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
    "grid = GridSearchCV(estimator=dfrst, param_grid=param_grid, cv = 5)\n",
    "grid_results = grid.fit(X_train_nd, y_train_nd)\n",
    "\n",
    "# Summarize the results in a readable format\n",
    "print(\"Best: {0}, using {1}\".format(grid_results.cv_results_['mean_test_score'], grid_results.best_params_))\n",
    "results_df = pd.DataFrame(grid_results.cv_results_)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de6ed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfb = RandomForestClassifier(n_estimators=128, max_depth=16)\n",
    "\n",
    "rfb.fit(X_train_nd, y_train_nd);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d591da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nd=rfb.predict(X_test_nd)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test_nd, y_pred_nd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b893643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "cm = metrics.confusion_matrix(y_test_nd, y_pred_nd)\n",
    "disc = ConfusionMatrixDisplay(cm)\n",
    "disc.plot()\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d393a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#treatment completed vs not\n",
    "tc = data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1071b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary(tc,[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f34715",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tc, test_tc = train_test_split(tc, test_size=0.2, shuffle=True)\n",
    "\n",
    "train_tc['REASON'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9bb361",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_majority = train_tc[train_tc.REASON==1]\n",
    "df_minority = train_tc[train_tc.REASON==0]\n",
    " \n",
    "# Upsample minority class\n",
    "df_min_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=195180,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_resampled_tc = pd.concat([df_min_upsampled, df_majority])\n",
    " \n",
    "# Display new class counts\n",
    "df_resampled_tc.REASON.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd772df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are the values we want to predict\n",
    "y_train_tc = np.array(df_resampled_tc['REASON'])\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "X_train_tc = df_resampled_tc.drop('REASON', axis = 1)\n",
    "# Saving feature names for later use\n",
    "feature_list_train_nd = list(X_train_tc.columns)\n",
    "# Convert to numpy array\n",
    "X_train_tc = np.array(X_train_tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d79c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are the values we want to predict\n",
    "y_test_tc = np.array(test_tc['REASON'])\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "X_test_tc = test_tc.drop('REASON', axis = 1)\n",
    "# Saving feature names for later use\n",
    "feature_list_train_tc = list(X_test_tc.columns)\n",
    "# Convert to numpy array\n",
    "X_test_tc= np.array(X_test_tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aff8fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train_tc, y_train_tc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f59120",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train_tc, y_train_tc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ffd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "cm = metrics.confusion_matrix(y_test_tc, y_pred_tc)\n",
    "disc = ConfusionMatrixDisplay(cm)\n",
    "disc.plot()\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe3e8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tcc = tc.loc[:, tc.columns != 'REASON']\n",
    "\n",
    "\n",
    "features = tcc.columns\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "# customized number \n",
    "num_features = 10 \n",
    "\n",
    "plt.figure(figsize=(10,100))\n",
    "plt.title('Feature Importances')\n",
    "\n",
    "# only plot the customized number of features\n",
    "plt.barh(range(num_features), importances[indices[-num_features:]], color='b', align='center')\n",
    "plt.yticks(range(num_features), [features[i] for i in indices[-num_features:]])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81060fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
